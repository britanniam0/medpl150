<html>
<head>
  <title>Reading 2: Nesrine Malik Reflection</title>
 <link rel="stylesheet" href="style.css"> 
</head>
  <body>
    <h1>Reflection on Nescrine Malik's "With 'AI slop' distorting our reality, the world is sleepwalking into disaster</h1>
<p>The term AI slop was completely new to me. After reading this article, it sparked feelings I didn’t expect and made me stop to think, something I realize I haven’t done in a while. It made me reflect deeply on how artificial intelligence is reshaping the way I experience truth online. Malik’s phrase AI slop captures the cheap, mass-produced, and often meaningless content that floods social media: synthetic images, fake videos, and posts made to look real but that clearly lack genuine human input or emotion. What stood out most was her warning that this constant flood of artificial material is dulling our ability to tell what’s real and what’s fake. It felt like she was holding up a mirror to my own scrolling habits, where I’ve started to doubt almost everything I see. Ironically, I was doomscrolling right before reading her article.<br>
I connected with Malik’s story about her “otherwise online-savvy elderly relative” who shares AI-generated images of the war in Sudan. Although I haven’t experienced that exact situation, I can relate. I often come across posts on social media that look convincing at first, especially dramatic photos or emotional quotes, and then later find out they were AI-generated or taken completely out of context. It’s frustrating how quickly false content spreads, especially when it plays on strong emotions. Malik’s point that people tend to believe what “chimes with their political desires” resonated with me, because I’ve noticed how algorithms feed us more of what we already agree with. That realization has made me more aware of my own reactions and more cautious about believing or sharing content too quickly.<br>
Malik’s argument goes beyond simply warning us about fake images. She treats AI slop as an ideological weapon. She points out that AI systems are trained on biased data, which means they often reproduce the same racial, gender, and cultural stereotypes already present in society. Her description of society as “sleepwalking into disaster” feels extreme but understandable. While I agree with her concern, I also believe that many people are beginning to wake up and become more skeptical. Schools, journalists, and educators are starting to emphasize AI literacy, which I see as an essential step toward addressing this problem. I wish Malik had explored this more because I believe education is the most powerful tool we have to fight misinformation.<br>
That being said, I don’t view AI as completely “bad.” Just like machines help make physical work easier, AI has helped me in practical ways: brainstorming ideas for art projects, creating study guides, and simplifying difficult readings. When used responsibly, AI can be an excellent tool. However, it should never replace human creativity or critical thought. Malik’s article reminded me that technology should serve as a support system, not a substitute for human judgment. I believe that when used together, human intelligence and AI can achieve incredible things, as long as we stay aware and intentional about how we use it.
</p>
<p><a href="readings.html">Back to Readings</a><p/>
<p><a href="index.html">Back to Home</a></p>
  </body>
</html>
